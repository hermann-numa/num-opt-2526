{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "01670400-d72a-4ac1-b70e-747f0cf7c4f8",
      "cell_type": "markdown",
      "source": "# Programmieraufgabe 07: Lokales und Globales Newton-Verfahren\n\nIn dieser Aufgabe wollen wir das lokale und globale Newton-Verfahren aus der Vorlesung implementieren und die Abhängigkeit der benötigten Iterationsschritte vom Startwert untersuchen.\n",
      "metadata": {}
    },
    {
      "id": "8ff636cc-d4b5-45af-8a5f-46047cf6b11b",
      "cell_type": "markdown",
      "source": "Tragen Sie zunächst in der folgenden Zelle **beide** Ihre Namen ein: ",
      "metadata": {}
    },
    {
      "id": "4d445f2f-2520-4feb-8be4-0d3089620853",
      "cell_type": "code",
      "source": "# Numerische Optimierungsverfahren der Wirtschaftsmathematik\n# Wintersemester 2025/2026\n# Übungsblatt 6 - Programmieraufgabe 6\n#\n# [Nachname], [Vorname]\n# [Vorname.Nachname@uni-a.de]\n# \n# [Nachname], [Vorname]\n# [Vorname.Nachname@uni-a.de]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "cb4865f0-0907-4c15-b72c-c7cc20f77cec",
      "cell_type": "code",
      "source": "import math\nimport numpy as np\nimport numpy.linalg as la\n\n# Diese Zeilen werden für die plots benötigt\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a2fb255b-a3c5-4f0e-896e-6615f2aa684e",
      "cell_type": "markdown",
      "source": "Implementieren Sie zunächst das Lokale Newton-Verfahren (Algorithmus 3.8). Das Verfahren soll abbrechen, wenn entweder die maximale Anzahl an Iterationen `kmax` durchgeführt wurde, oder der Abstand der Funktionswerte zweier Iterationen $|f(x^{(k)}) - f(x^{(k-1)})|$ kleiner als die Toleranz `tol` ist.\n\nFür das Lösen der Newton-Gleichung dürfen sie dabei die Funktion `la.solve` verwenden.",
      "metadata": {}
    },
    {
      "id": "f4d13641-59ec-4f64-aa73-c9d45b711f70",
      "cell_type": "code",
      "source": "def newton_local(f, g, h, x_0, tol, kmax):\n    '''\n        Lokales Newton-Verfahren\n\n        Parameter:\n            f        : Die zu minimierende Funktion f\n            g        : Funktion, die den Gradienten von f zurückgibt\n            h        : Funktion, die die Hesse-Matrix von f zurückgibt\n            x_0      : Startvektor\n            tol      : Abbruchkriterium\n            kmax     : Maximale Anzahl an Iterationen\n\n        Rückgabewert:\n            iterates : Vektor der Iterierten. Dabei ist iterates[-1,:]\n                       der Rückgabewert und len(iterates) - 1 die Anzahl\n                       an Iterationen\n    '''\n    \n    #  Initialisierung\n    n = x_0.shape[0]\n    iterates = np.ones((kmax + 1, n))\n    x = np.copy(x_0)\n    iterates[0,:] = x\n    f_old = f(x)\n    f_diff = np.inf\n\n    ???\n    \n    return iterates",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8cb72ded-9322-411e-8f86-d5138dec113e",
      "cell_type": "markdown",
      "source": "Sie können die Folgende Zelle zum Testen Ihrer Funktion verwenden. Dabei sollte das lokale Newton-Verfahren in zwei Schritten zum Minimum (0, 0) konvergieren (Hier wird ein Schritt benötigt, um zum Minimum zu gelangen, und ein weiterer, um festzustellen, dass sich der Funktionswert nicht mehr ändert).",
      "metadata": {}
    },
    {
      "id": "6f465b79-3b79-412e-a6c0-ec8e9b1b36f4",
      "cell_type": "code",
      "source": "f = lambda x : x[0]**2 + x[0]**2\ng = lambda x : np.array([2*x[0], 2*x[1]])\nh = lambda x : np.array([[2, 0], [0, 2]])\niterates = newton_local(f, g, h, np.array([1.5, -99]), 1e-16, 100)\nprint(iterates)\nprint(f'newton_local konvergiert in {len(iterates)-1} Schritten zu {iterates[-1]}.')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "53ded499-9896-4ff2-a667-175a90c901dd",
      "cell_type": "markdown",
      "source": "Implementieren Sie nun die Armijo-Schrittweitenregel für das globale Newton-Verfahren. Sie können wieder Ihre Lösung aus Aufgabe 3 größtenteils wiederverwenden, achten Sie aber darauf, dass die Funktion `f` nicht unbedingt quadratisch sein muss.",
      "metadata": {}
    },
    {
      "id": "6090cfd9-5cac-4c31-851a-4407de5b0209",
      "cell_type": "code",
      "source": "def armijo_step_size(f, g, x, direction, beta = 0.5, gamma = 1e-4):\n    '''\n        Armijo-Schrittweitenregel\n\n        Parameter:\n            f           : Die zu minimierende Funktion f\n            g           : Der Gradient von f\n            x           : Aktueller Wert der Iteration\n            direction   : Aktuelle Richtung des Abstiegsverfahrens\n            beta, gamma : Parameter der Armijo-Schritweitenregel\n\n        Rückgabewert:\n            alpha: Armijo-Schrittweite\n    '''\n    \n    if beta <= 0 or beta >= 1:\n        raise ValueError(f'Der Parameter beta muss im Intervall (0,1) liegen, aber beta={beta}!')\n    if gamma <= 0 or gamma >= 1:\n        raise ValueError(f'Der Parameter gamma muss im Intervall (0,1) liegen, aber gamma={gamma}!')\n\n   ???\n\n    return alpha",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f9468aa5-2d32-4696-ba18-f9a90f78da38",
      "cell_type": "markdown",
      "source": "Mit der folgenden Zelle können Sie die Schrittweite testen. Dabei sollte das Ergebnis der ersten Auswerktung `0.5625` und der zweiten `0.75` sein.\n\nDie dritte Auswertung testet den Fall, dass `direction` keine Abstiegsrichtung ist. Dies kann im Newton-Verfahren leicht auftreten, z.B. wenn das exakte Minimum erreicht wird. Geben Sie in diesem Fall `alpha = 1` zurück und vermeiden Sie Endlosschleifen!",
      "metadata": {}
    },
    {
      "id": "31fd364d-dbd7-4ae6-b9c4-f0a6864a28fb",
      "cell_type": "code",
      "source": "f = lambda x : np.array([math.sin(x[0] * math.pi)])\ng = lambda x : np.array([math.cos(x[0] * math.pi)])\nprint(armijo_step_size(f, g, np.array([0.0]), np.array([-1.0]), beta = 0.75, gamma = 0.99))\nprint(armijo_step_size(f, g, np.array([0.0]), np.array([-1.0]), beta = 0.75, gamma = 0.1))\nprint(armijo_step_size(f, g, np.array([0.0]), np.array([ 0.0]), beta = 0.75, gamma = 0.1))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2f4eff11-43bc-490f-bba5-6d929a1470b1",
      "cell_type": "markdown",
      "source": "Als letztes implementieren Sie das globale Newton-Verfahren (Algorithmus 3.9).\n\nWie im lokalen Newton-Verfahren dürfen Sie `la.solve` zum Lösen der Newtongleichung verwenden. Um zu testen, ob die Hesse-Matrix numerisch nicht invertierbar ist, verwenden Sie z.B. `abs(la.cond(hessian)) < 1e-14`.",
      "metadata": {}
    },
    {
      "id": "c30b3715-102b-4a45-9132-08cb41246809",
      "cell_type": "code",
      "source": "def newton_global(f, g, h, x_0, tol, kmax, step_size, delta = 0.01, p = 3):\n    '''\n        Globales Newton-Verfahren\n\n        Parameter:\n            f         : Die zu minimierende Funktion f\n            g         : Funktion, die den Gradienten von f zurückgibt\n            h         : Funktion, die die Hesse-Matrix von f zurückgibt\n            x_0       : Startvektor\n            tol       : Abbruchkriterium\n            kmax      : Maximale Anzahl an Iterationen\n            step_size : Funktion, die als Argumente f, g, die aktuelle \n                        Iterierte x und die aktuelle Richtung direction \n                        erhält und eine Schrittweite alpha zurückgibt\n            delta, p  : Parameter des Globalen Newton-Verfahrens\n\n        Rückgabewert:\n            iterates : Vektor der Iterierten. Dabei ist iterates[-1,:]\n                       der Rückgabewert und len(iterates) - 1 die Anzahl\n                       an Iterationen\n    '''\n\n    #  Initialisierung\n    n = x_0.shape[0]\n    iterates = np.ones((kmax + 1, n))\n    x = np.copy(x_0)\n    iterates[0,:] = x\n    k = 1\n    f_old = f(x)\n    f_diff = np.inf\n\n    ???\n    \n    return iterates",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1cded2de-1646-4f1a-a377-2fe68d4e0296",
      "cell_type": "markdown",
      "source": "Testen Sie wieder Ihre Implementierung mit der folgenden Zelle. Auch `newton_global` sollte in zwei Schritten zu (0, 0) konvergieren (Wie oben wird der zweite Schritt nur benötigt, um das Abbruchkriterium zu verifizieren).",
      "metadata": {}
    },
    {
      "id": "1fa8c947-a6c3-43a7-b62f-3e6d21519772",
      "cell_type": "code",
      "source": "f = lambda x : x[0]**2 + x[0]**2\ng = lambda x : np.array([2*x[0], 2*x[1]])\nh = lambda x : np.array([[2, 0], [0, 2]])\niterates = newton_global(f, g, h, np.array([1.5, -99]), 1e-16, 100, armijo_step_size)\nprint(iterates)\nprint(f'newton_local konvergiert in {len(iterates)-1} Schritten zu {iterates[-1]}.')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "56c35eba-115f-4df9-acdc-b9c35654f0bb",
      "cell_type": "markdown",
      "source": "Im Folgenden definieren wir uns drei Testfunktionen: Die Rosenbrock-Funktion $f_R(x_1, x_2) = 100(x_2 - x_1^2)^2 + (1 - x_1)^2$ aus Beispiel 3.48, die Himmelblau-Funktion $f_H(x_1, x_2) = (x_1^2 + x_2 - 11)^2 + (x_1 + x_2^2 - 7)^2$, die ebenfalls eine beliebte Testfunktion für Optimierungsalgorithmen ist, und die Funktion $f_S(x_1, x_2) = x_1 (x_1^2 - 2 x_2^2) + 0.15(x_1^2 + x_2^2 - 1)^2$.",
      "metadata": {}
    },
    {
      "id": "72827f52-5382-4f5f-ba4d-ab01976c8b53",
      "cell_type": "code",
      "source": "def  rosenbrock_funktion(x):\n    return 100.0 *(x[1] - x[0]**2)**2 + (1.0 - x[0])**2\n\ndef  rosenbrock_gradient ( x ) :\n    return np.array(\n        [\n            400.0 * x[0] * (x[0]**2 - x[1]) + 2.0 * (x[0] - 1.0),\n            200.0 * (x[1] - x[0]**2),\n        ],\n    )\n\ndef  rosenbrock_hesse(x):\n    return np.array(\n        [\n            [\n                1200.0 * x[0]**2 - 400.0 * x[1] + 2.0, \n                -400.0 * x[0],\n            ],\n            [\n                -400.0 * x[0],\n                200.0,\n            ],\n        ],\n    )\nrosenbrock = (rosenbrock_funktion, rosenbrock_gradient, rosenbrock_hesse)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9a4ec70c-f0fc-48dd-8b7c-a66de3e34182",
      "cell_type": "code",
      "source": "def himmelblau_funktion(x):\n    return (x[0]**2 + x[1] - 11.0 )**2 + (x[0] + x[1]**2 - 7.0)**2\n\ndef  himmelblau_gradient(x):\n    return np.array(\n        [\n            4.0 * x[0] * (x[0]**2 + x[1] - 10.5) + 2.0 * x[1]**2 - 14.0, \n            4.0 * x[1] * (x[1]**2 + x[0] - 6.5 ) + 2.0 * x[0]**2 - 22.0,\n        ],\n    )\n    \ndef  himmelblau_hesse(x):\n    return np.array(\n        [\n            [\n                12.0 * x[0]**2 + 4.0 * x[1] - 42.0,\n                4.0 * (x[0] + x[1]),\n            ],\n            [\n                4.0 * (x[0] + x[1]),\n                12.0 * x[1]**2 + 4.0 * x[0] - 26.0,\n            ],\n        ],\n    )\nhimmelblau = (himmelblau_funktion, himmelblau_gradient, himmelblau_hesse)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "89b90132-c54a-404f-8578-375667643344",
      "cell_type": "code",
      "source": "def sattel_funktion(x):\n    return x[0] * (x[0]**2 - 2.0 * x[1]**2) + 0.15 * (x[0]**2 + x[1]**2 - 1.0)**2\n\ndef sattel_gradient(x):\n    return np.array(\n        [\n            x[0]**2 * (0.6 * x[0] + 3.0) + x[1]**2 * (0.6 * x[0] - 2.0) - 0.6 * x[0],\n            0.6 * x[1] * (x[0]**2 + x[1]**2 - 1) - 4.0 * x[0] * x[1],\n        ]\n    )\n\ndef sattel_hesse(x):\n    xx = x[0]\n    yy = x[1]\n    x2 = xx * xx\n    y2 = yy * yy\n    xy = xx * yy\n    return np.array(\n        [\n            [\n                6.0 * x[0] + 1.8 * x[0]**2 + 0.6 * x[1]**2 - 1.0,\n                1.2 * x[0] * x[1] - 4.0 * x[1],\n            ],\n            [\n                1.2  * x[0] * x[1] - 4.0 * x[1],\n                -4.0 * x[0] + 1.8 * x[1]**2 + 0.6 * x[0]**2 - 1.0,\n            ],\n        ],\n    )\n\nsattel = (sattel_funktion, sattel_gradient, sattel_hesse)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5c595b68-55f4-4163-8167-9f9f727a520e",
      "cell_type": "markdown",
      "source": "Mit der Rosenbrock-Funktion können Sie nun nocheinmal Ihre Implementierung testen. Dabei sollten beide zum selben Minimum (1, 1) konvergieren, und `newton_local` ungefähr 7, `newton_global` ungefähr 22 Schritte benötigen.",
      "metadata": {}
    },
    {
      "id": "d9047595-85f5-445f-8c2e-c173b1289ab7",
      "cell_type": "code",
      "source": "iterates = newton_local(*rosenbrock, np.array([-1.2, 1.0]), 1e-16, 100)\nprint(f'newton_local konvergiert in {len(iterates)-1} Schritten zu {iterates[-1]}.')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "087f6af7-4cd5-466e-8d01-6c63420928b5",
      "cell_type": "code",
      "source": "iterates = newton_global(*rosenbrock, np.array([-1.2, 1.0]), 1e-16, 100, armijo_step_size)\nprint(f'newton_global konvergiert in {len(iterates)-1} Schritten zu {iterates[-1]}.')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "32e8db13-bd62-4b98-b600-1190b0ecaf9d",
      "cell_type": "markdown",
      "source": "Abschließend können wir nun das lokale und das globale Newton-Verfahren und ihre Abhängigkeit vom Startwert untersuchen. Die Plots zeigen dabei jeweils die benötigten Iterationen bis zur Konvergenz der Verfahren. Sie können gerne die Auflösung des Gitters erhöhen, dies dauert aber natürlich entsprechend länger.",
      "metadata": {}
    },
    {
      "id": "8325f51a-005d-4fdb-b057-2f441eb86405",
      "cell_type": "code",
      "source": "from util.plotting_07 import plot_07\n\nresolution = (60, 40)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "18409339-9a3f-4849-884a-4f1e7a858396",
      "cell_type": "code",
      "source": "x_range = (-1.5, 1.5)\ny_range = (-0.4, 1.6)\nplot_07(newton_local, newton_global, armijo_step_size, *rosenbrock, *resolution, *x_range, *y_range)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c5d05f5c-14ef-4855-a478-506350ea41ee",
      "cell_type": "code",
      "source": "x_range = (-7.5, 7.5)\ny_range = (-5.0, 5.0)\nplot_07(newton_local, newton_global, armijo_step_size, *himmelblau, *resolution, *x_range, *y_range)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e7f7f635-079a-414c-a5de-28c7a9d0ea78",
      "cell_type": "code",
      "source": "x_range = (-9.0, 6.0)\ny_range = (-5.0, 5.0)\nplot_07(newton_local, newton_global, armijo_step_size, *sattel, *resolution, *x_range, *y_range)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ec2aabfc-d131-4953-9c80-403b12e716d7",
      "cell_type": "markdown",
      "source": "Besonders bei der letzten Funktion fällt auf, dass das globale Newton-Verfahren auch für Werte konvergiert, für die das lokale Newton-Verfahren in der vorgegebenen Iterationsanzahl keine Lösung liefert (was als gelbe Bereiche im Plot sichtbar ist).",
      "metadata": {}
    }
  ]
}