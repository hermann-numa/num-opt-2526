{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "477be0df-94af-421d-ba99-0c8681abbeaf",
      "cell_type": "markdown",
      "source": "# Programmieraufgabe 08: BFGS und iBFGS\n\nÄhnlich wie in Programmieraufgabe 7 das Newton-Verfahren, sollen dieses mal das BFGS-Verfahren und das inverse BFGS-Verfahren untersucht werden.",
      "metadata": {}
    },
    {
      "id": "54f71c50-ef40-4b62-9799-50453b83c43b",
      "cell_type": "markdown",
      "source": "Tragen Sie zunächst in der folgenden Zelle **beide** Ihre Namen ein:",
      "metadata": {}
    },
    {
      "id": "7f964e0a-4a46-4b54-a930-cbb2fd19a0b8",
      "cell_type": "code",
      "source": "# Numerische Optimierungsverfahren der Wirtschaftsmathematik\n# Wintersemester 2025/2026\n# Übungsblatt 8 - Programmieraufgabe 8\n#\n# [Nachname], [Vorname]\n# [Vorname.Nachname@uni-a.de]\n# \n# [Nachname], [Vorname]\n# [Vorname.Nachname@uni-a.de]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "36151a5b-eaa1-4c3d-9cd9-6d9442adf5a8",
      "cell_type": "markdown",
      "source": "Führen Sie die folgende Zelle zu Beginn einmal aus, selbst wenn Sie ihre Importe selbst definieren. Sie werden unter anderem auch für das Plotting benötigt.",
      "metadata": {}
    },
    {
      "id": "54b1f4bb-fc4c-4b98-b40c-ed38776eea12",
      "cell_type": "code",
      "source": "import numpy as np\nimport numpy.linalg as la\n\nimport matplotlib.pyplot as plt",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "75a96cc5-481e-4f49-a908-5bb85ea71697",
      "cell_type": "markdown",
      "source": "Sie können dieses mal bereits vorimplementierte Funktionen für die Schrittweiten benutzen. Beide erhalten als Argumente eine Funktion `f`, ihren Gradienten `g`, eine aktuelle Iterierte `x` und eine Suchrichtung `direction` und geben eine Schrittweite `alpha` zurück. `x` und `direction` sind dabei Numpy-Arrays mit den gleichen Dimensionen.",
      "metadata": {}
    },
    {
      "id": "ecf44849-0d28-4dd3-8617-79dfe9685df8",
      "cell_type": "code",
      "source": "from util.step_sizes_08 import wolfe_powell_step_size, constant_step_size\n\n#Beispiel\nf = lambda x : x[0]**2 + x[1]**2\ng = lambda x : np.array([2*x[0], 2*x[1]])\nx = np.array([0.1, 1.0])\ndirection = -g(x)\n\nprint(wolfe_powell_step_size(f, g, x, direction))\nprint(constant_step_size(f, g, x, direction))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4ac9c458-9719-457a-b3dc-f250e22ae25f",
      "cell_type": "markdown",
      "source": "Implementieren Sie nun das globale inverse BFGS-Verfahren (Algorithmus 3.16). Beachten Sie dabei folgende Unterschiede zum Skript:\n- Erlauben Sie nicht nur (wie im Skript) die Wolfe-Powell-Regel, sondern eine beliebige Schrittweite. Verwenden Sie dazu das Argument `step_size`, das später mit den Funktionen `wolfe_powell_step_size` und `constant_step_size` von oben aufgerufen wird.\n- Das Verfahren soll stoppen, wenn $|f(x^{(k+1)}) - f(x^{(k)})| < \\text{tol}$ erfüllt ist oder die maximale Anzahl an Iterationen ausgeführt wurde. Den Gradienten müssen Sie dabei, anders als im Skript, nicht überprüfen.\n\n**Tipp:** Achten Sie zusätzlich darauf, dass Sie tatsächlich *Matrizen* als Updates verwenden, denn `v @ w.T` berechnet etwas unerwartet das Skalarprodukt der Vektoren `v` und `w`, also $v^Tw$. Für $v w^T$ verwenden Sie zum Beispiel `np.outer(v, w)`. ",
      "metadata": {}
    },
    {
      "id": "95c425d3-be70-457b-93ce-9ed90e99339f",
      "cell_type": "code",
      "source": "def iBFGS(f, g, x_0, step_size, B_0 = None, tol = 1e-16, kmax = 100):\n    '''\n        Globales inverses BFGS-Verfahren\n\n        Parameter:\n            f         : Die zu minimierende Funktion f\n            g         : Funktion, die den Gradienten von f zurückgibt\n            x_0       : Startvektor\n            step_size : Funktion, die als Argumente f, g, die aktuelle \n                        Iterierte x und die aktuelle Richtung direction \n                        erhält und eine Schrittweite alpha zurückgibt\n            B_0       : Initiale Approximation der (inversen) Hesse-Matrix.\n                        Als Default-Wert (B_0 is None) verwenden Sie die\n                        Einheitsmatrix\n            tol       : Abbruchkriterium\n            kmax      : Maximale Anzahl an Iterationen\n\n        Rückgabewert:\n            iterates : Vektor der Iterierten. Dabei ist iterates[0,:]\n                       der Startwert, iterates[-1,:] der Rückgabewert\n                       und len(iterates) - 1 die Anzahl an Iterationen\n    '''\n\n    ???",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "659230d1-31dd-420a-b4c9-8d5590a07b56",
      "cell_type": "markdown",
      "source": "Als Testfunktionen verwenden wir wieder die Rosenbrock, Himmelblau und Sattel Funktionen aus Aufgabe 7. Aus Platzgründen importieren wir sie hier, die Definition entspricht aber exakt der vorherigen Aufgabe.",
      "metadata": {}
    },
    {
      "id": "21bc553f-fbd7-4574-af43-04599703041e",
      "cell_type": "code",
      "source": "from util.functions_08 import rosenbrock_funktion, rosenbrock_gradient, himmelblau_funktion, himmelblau_gradient, sattel_funktion, sattel_gradient",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7549333c-94e7-439c-8ea1-2807ff0d825a",
      "cell_type": "markdown",
      "source": "Das globale inverse BFGS-Verfahren sollte in ca. 34 Schritten in die Nähe des Minimums (1, 1) konvergieren:",
      "metadata": {}
    },
    {
      "id": "cc6a396f-da0f-410f-a20f-239dd22645f2",
      "cell_type": "code",
      "source": "iterates = iBFGS(rosenbrock_funktion, rosenbrock_gradient, np.array([-1.3, 1.0]), wolfe_powell_step_size, tol = 1e-8)\nprint(f'Das globale inverse BFGS-Verfahren konvergiert in {len(iterates)-1} Schritten zu {iterates[-1,:]}.')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "fbea6cc2-9e89-4732-a963-5c1dd05dceaf",
      "cell_type": "markdown",
      "source": "Implementieren Sie als nächstes das globale BFGS-Verfahren. Dieses ist genau so wie das inverse BFGS von oben definiert, nur dass die neue Richtung nicht als $d^{(k)} = -B_k\\nabla f(x^{(k)}$, sondern als Lösung von $H_kd^{(k)} = - \\nabla f(x^{(k)})$ berechnet wird und für $H_{k+1}$ die BFGS-Formel (3.25) verwendet wird. Alles übrige (Schrittweiten, Abbruchkriterium, ...) soll der Funktion `iBFGS` entsprechen.",
      "metadata": {}
    },
    {
      "id": "a394d0c2-039d-4400-8375-baed3caa458c",
      "cell_type": "code",
      "source": "def BFGS(f, g, x_0, step_size, H_0 = None, tol = 1e-16, kmax = 100):\n    '''\n        Globales inverses BFGS-Verfahren\n\n        Parameter:\n            f         : Die zu minimierende Funktion f\n            g         : Funktion, die den Gradienten von f zurückgibt\n            x_0       : Startvektor\n            step_size : Funktion, die als Argumente f, g, die aktuelle \n                        Iterierte x und die aktuelle Richtung direction \n                        erhält und eine Schrittweite alpha zurückgibt\n            H_0       : Initiale Approximation der Hesse-Matrix. Als\n                        Default-Wert (H_0 is None) verwenden Sie die\n                        Einheitsmatrix\n            tol       : Abbruchkriterium\n            kmax      : Maximale Anzahl an Iterationen\n\n        Rückgabewert:\n            iterates : Vektor der Iterierten. Dabei ist iterates[0,:]\n                       der Startwert, iterates[-1,:] der Rückgabewert\n                       und len(iterates) - 1 die Anzahl an Iterationen\n    '''\n\n    ???",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "41060019-ab4b-4444-b140-a1e935a16df7",
      "cell_type": "markdown",
      "source": "Da beide Verfahren aufgrund der Sherman-Morrison-Woodbury-Formel die selben Iterationen definieren, sollten die Folgen $x^{(k)}$ bis auf numerische Fehler übereinstimmen:",
      "metadata": {}
    },
    {
      "id": "cdd3923e-7595-44cc-8f71-601481daef9d",
      "cell_type": "code",
      "source": "iterates_iBFGS = iBFGS(rosenbrock_funktion, rosenbrock_gradient, np.array([-1.3, 1.0]), wolfe_powell_step_size, B_0 = np.array([[0.5, 0.0], [0.0, 0.5]]), tol = 1e-8)\niterates_BFGS  =  BFGS(rosenbrock_funktion, rosenbrock_gradient, np.array([-1.3, 1.0]), wolfe_powell_step_size, H_0 = np.array([[2.0, 0.0], [0.0, 2.0]]), tol = 1e-8)\n\nassert len(iterates_iBFGS) == len(iterates_BFGS)\nfor i in range(len(iterates_iBFGS)):\n    #print(f'iBFGS: {iterates_iBFGS[i]}\\t\\tBFGS: {iterates_BFGS[i]}\\t\\tdifference: {la.norm(iterates_iBFGS[i] - iterates_BFGS[i])}')\n    assert la.norm(iterates_iBFGS[i] - iterates_BFGS[i]) < 1e-8",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "312ed9a2-eea7-48c5-aac2-eff2ee63fb66",
      "cell_type": "markdown",
      "source": "Wie in Programmieraufgabe 07 vergleichen wir nun lokale und globale Verfahren. Für das lokale Verfahren verwenden wir einfach die Schrittweitenregel `constant_step_size`. Da `BFGS` und `iBFGS` bis auf numerische Fehler die selben Iterationen erzeugen, erzeugen wir die Grafiken im Folgenden nur für das inverse BFGS-Verfahren. Sie können aber gerne auch ihre Implementierung des BFGS-Verfahren testen, in dem Sie im Folgenden `iBFGS` durch `BFGS` ersetzen.",
      "metadata": {}
    },
    {
      "id": "8640f21c-d064-4720-bd92-a882f446b2b7",
      "cell_type": "code",
      "source": "# Diese Zeilen werden für die plots benötigt\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\nfrom util.plotting_08 import plot_08\n\nresolution = (45, 30)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "85aa7615-47f1-4056-934c-6816b0f2b15a",
      "cell_type": "code",
      "source": "x_range = (-1.5, 1.5)\ny_range = (-0.4, 1.6)\nplot_08(iBFGS, constant_step_size, wolfe_powell_step_size, rosenbrock_funktion, rosenbrock_gradient, *resolution, *x_range, *y_range, kmax = 100, tol = 1e-16)\n\n# Das lokale iBFGS-Verfahren hat große gelbe Bereiche, in denen in 100 Schritten keine Konvergenz auftritt",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9140fc30-026b-412b-87ed-47c8c46da4c9",
      "cell_type": "code",
      "source": "x_range = (-7.5, 7.5)\ny_range = (-5.0, 5.0)\nplot_08(iBFGS, constant_step_size, wolfe_powell_step_size, himmelblau_funktion, himmelblau_gradient, *resolution, *x_range, *y_range, kmax = 100, tol = 1e-16)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e9f35f04-d46b-4de5-b792-13f2a4acdf0e",
      "cell_type": "code",
      "source": "x_range = (-9.0, 6.0)\ny_range = (-5.0, 5.0)\nplot_08(iBFGS, constant_step_size, wolfe_powell_step_size, sattel_funktion, sattel_gradient, *resolution, *x_range, *y_range, kmax = 100, tol = 1e-16)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}